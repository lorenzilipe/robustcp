{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os\n",
    "import sympy\n",
    "from sympy import Symbol as sb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "RANDOM_STATE = 42"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is the data used for the regression experiments in the VRCP paper. It is generated by the PettingZoo Multi-Particle Environment (MPE) library (Terry et al. (2021)) for deep reinforcement learning using some specified parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_folder = 'data/mpe-data/spread/obs/example'\n",
    "seed_dirs = [\n",
    "    d for d in os.listdir(base_folder)\n",
    "    if d.startswith(\"seed_\") and os.path.isdir(os.path.join(base_folder, d))\n",
    "]\n",
    "\n",
    "initials_dict = {}\n",
    "rewards_sum_dict = {}\n",
    "\n",
    "for d in seed_dirs:\n",
    "    seed_id = d.split('_', 1)[1]  # get the unique seed identifier\n",
    "    folder = os.path.join(base_folder, d)\n",
    "    state_file = os.path.join(folder, 'state_initial.npy')\n",
    "    rewards_file = os.path.join(folder, 'rewards_traj_0.npy')\n",
    "    \n",
    "    if os.path.exists(state_file) and os.path.exists(rewards_file):\n",
    "        # Load state_initial.npy\n",
    "        state_initial = np.load(state_file, allow_pickle=True)\n",
    "        initials_dict[seed_id] = state_initial\n",
    "        \n",
    "        # Load rewards_traj_0.npy and sum over column 0\n",
    "        rewards_traj = np.load(rewards_file, allow_pickle=True)\n",
    "        rewards_sum = rewards_traj[:, 0].sum()\n",
    "        rewards_sum_dict[seed_id] = rewards_sum\n",
    "\n",
    "# Create dataframes with the seed identifier as index\n",
    "X = pd.DataFrame.from_dict(initials_dict, orient='index')\n",
    "y = pd.DataFrame.from_dict(rewards_sum_dict, orient='index', columns=['reward_sum'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "      <th>15</th>\n",
       "      <th>16</th>\n",
       "      <th>17</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6243</th>\n",
       "      <td>-4.638947</td>\n",
       "      <td>2.580580</td>\n",
       "      <td>-0.028328</td>\n",
       "      <td>0.248217</td>\n",
       "      <td>-3.924162</td>\n",
       "      <td>-4.063509</td>\n",
       "      <td>-0.416743</td>\n",
       "      <td>0.072911</td>\n",
       "      <td>-0.301039</td>\n",
       "      <td>-3.113701</td>\n",
       "      <td>-0.252470</td>\n",
       "      <td>-0.195096</td>\n",
       "      <td>-5.813191</td>\n",
       "      <td>3.822884</td>\n",
       "      <td>-5.418576</td>\n",
       "      <td>0.906666</td>\n",
       "      <td>-6.299335</td>\n",
       "      <td>4.016806</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31994</th>\n",
       "      <td>4.281446</td>\n",
       "      <td>-3.261618</td>\n",
       "      <td>0.010150</td>\n",
       "      <td>-0.188225</td>\n",
       "      <td>4.297802</td>\n",
       "      <td>4.208184</td>\n",
       "      <td>0.092497</td>\n",
       "      <td>-0.479421</td>\n",
       "      <td>4.304405</td>\n",
       "      <td>1.721131</td>\n",
       "      <td>0.436334</td>\n",
       "      <td>0.264733</td>\n",
       "      <td>4.589279</td>\n",
       "      <td>-3.624757</td>\n",
       "      <td>2.610501</td>\n",
       "      <td>-2.089010</td>\n",
       "      <td>2.058335</td>\n",
       "      <td>-2.271987</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35508</th>\n",
       "      <td>3.031222</td>\n",
       "      <td>1.169525</td>\n",
       "      <td>-0.074642</td>\n",
       "      <td>0.332341</td>\n",
       "      <td>-2.728792</td>\n",
       "      <td>4.987189</td>\n",
       "      <td>-0.359577</td>\n",
       "      <td>0.304756</td>\n",
       "      <td>-1.631607</td>\n",
       "      <td>-1.649202</td>\n",
       "      <td>-0.002981</td>\n",
       "      <td>0.405769</td>\n",
       "      <td>2.303867</td>\n",
       "      <td>1.535052</td>\n",
       "      <td>4.059220</td>\n",
       "      <td>0.225018</td>\n",
       "      <td>1.071398</td>\n",
       "      <td>1.865327</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90144</th>\n",
       "      <td>-1.374741</td>\n",
       "      <td>0.999021</td>\n",
       "      <td>-0.418587</td>\n",
       "      <td>0.021922</td>\n",
       "      <td>1.123773</td>\n",
       "      <td>-2.763672</td>\n",
       "      <td>-0.340124</td>\n",
       "      <td>0.335538</td>\n",
       "      <td>-1.485562</td>\n",
       "      <td>-2.459087</td>\n",
       "      <td>-0.289571</td>\n",
       "      <td>0.358079</td>\n",
       "      <td>-0.304709</td>\n",
       "      <td>2.579039</td>\n",
       "      <td>-3.294965</td>\n",
       "      <td>-1.250610</td>\n",
       "      <td>-1.774850</td>\n",
       "      <td>1.165915</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23835</th>\n",
       "      <td>-0.060958</td>\n",
       "      <td>-1.434050</td>\n",
       "      <td>-0.214032</td>\n",
       "      <td>0.328670</td>\n",
       "      <td>3.629799</td>\n",
       "      <td>4.153177</td>\n",
       "      <td>0.427419</td>\n",
       "      <td>0.381438</td>\n",
       "      <td>-3.286709</td>\n",
       "      <td>4.002148</td>\n",
       "      <td>0.473706</td>\n",
       "      <td>-0.422327</td>\n",
       "      <td>-0.989097</td>\n",
       "      <td>0.159420</td>\n",
       "      <td>2.319946</td>\n",
       "      <td>-1.123382</td>\n",
       "      <td>-0.530721</td>\n",
       "      <td>-0.815355</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             0         1         2         3         4         5         6   \\\n",
       "6243  -4.638947  2.580580 -0.028328  0.248217 -3.924162 -4.063509 -0.416743   \n",
       "31994  4.281446 -3.261618  0.010150 -0.188225  4.297802  4.208184  0.092497   \n",
       "35508  3.031222  1.169525 -0.074642  0.332341 -2.728792  4.987189 -0.359577   \n",
       "90144 -1.374741  0.999021 -0.418587  0.021922  1.123773 -2.763672 -0.340124   \n",
       "23835 -0.060958 -1.434050 -0.214032  0.328670  3.629799  4.153177  0.427419   \n",
       "\n",
       "             7         8         9         10        11        12        13  \\\n",
       "6243   0.072911 -0.301039 -3.113701 -0.252470 -0.195096 -5.813191  3.822884   \n",
       "31994 -0.479421  4.304405  1.721131  0.436334  0.264733  4.589279 -3.624757   \n",
       "35508  0.304756 -1.631607 -1.649202 -0.002981  0.405769  2.303867  1.535052   \n",
       "90144  0.335538 -1.485562 -2.459087 -0.289571  0.358079 -0.304709  2.579039   \n",
       "23835  0.381438 -3.286709  4.002148  0.473706 -0.422327 -0.989097  0.159420   \n",
       "\n",
       "             14        15        16        17  \n",
       "6243  -5.418576  0.906666 -6.299335  4.016806  \n",
       "31994  2.610501 -2.089010  2.058335 -2.271987  \n",
       "35508  4.059220  0.225018  1.071398  1.865327  \n",
       "90144 -3.294965 -1.250610 -1.774850  1.165915  \n",
       "23835  2.319946 -1.123382 -0.530721 -0.815355  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reward_sum</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6243</th>\n",
       "      <td>-14.696764</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31994</th>\n",
       "      <td>-13.417332</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35508</th>\n",
       "      <td>-10.716178</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90144</th>\n",
       "      <td>-12.103149</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23835</th>\n",
       "      <td>-11.703057</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       reward_sum\n",
       "6243   -14.696764\n",
       "31994  -13.417332\n",
       "35508  -10.716178\n",
       "90144  -12.103149\n",
       "23835  -11.703057"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train-test-split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_size = 2000\n",
    "calib_size = 2000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Split the data into training/calibration and testing sets\n",
    "X_train_calib, X_test, y_train_calib, y_test = train_test_split(X, y, test_size=test_size, random_state=RANDOM_STATE)\n",
    "\n",
    "# Split the training/calibration set into training and calibration sets\n",
    "X_train, X_calib, y_train, y_calib = train_test_split(X_train_calib, y_train_calib, test_size=calib_size, random_state=RANDOM_STATE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Injecting ranges (symbolic expr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.spatial import ConvexHull\n",
    "import itertools\n",
    "\n",
    "# useful functions\n",
    "\n",
    "symbol_id = -1\n",
    "def create_symbol(suffix=''):\n",
    "    global symbol_id\n",
    "    symbol_id += 1\n",
    "    name = f'e{symbol_id}_{suffix}' if suffix else f'e{symbol_id}'\n",
    "    return sympy.Symbol(name=name)\n",
    "\n",
    "\n",
    "scaler_symbols = set([sb(f'k{i}') for i in range(X_calib.shape[1]+1)])\n",
    "linearization_dict = dict()\n",
    "reverse_linearization_dict = dict()\n",
    "\n",
    "\n",
    "def sample_data(imputed_datasets, uncert_inds=[], seed=42):\n",
    "    imp_np = np.array(imputed_datasets)\n",
    "    if len(uncert_inds) == 0:\n",
    "        uncert_inds = list(itertools.product(range(imp_np.shape[1]),range(imp_np.shape[2])))\n",
    "    np.random.seed(seed)\n",
    "    choices = np.random.choice(np.arange(imp_np.shape[0]), len(uncert_inds), replace=True)\n",
    "    sample_result = imputed_datasets[0].copy()\n",
    "    for i, ind in enumerate(uncert_inds):\n",
    "        sample_result[ind[0]][ind[1]] = imputed_datasets[choices[i]][ind[0]][ind[1]]\n",
    "    return sample_result\n",
    "\n",
    "\n",
    "def linearization(expr_ls):\n",
    "    processed_expr_ls = [0 for _ in range(len(expr_ls))]\n",
    "    for expr_id, expr in enumerate(expr_ls):\n",
    "        # Do not support monomial expr currently, e.g., expr = 1.5*e1. \n",
    "        # At lease two monomials in expr, e.g., expr = 1.5*e1 + 2.\n",
    "        if not(expr.free_symbols):\n",
    "            processed_expr_ls[expr_id] += expr\n",
    "            continue\n",
    "        expr = expr.expand()\n",
    "        for arg in expr.args:\n",
    "            if not(arg.free_symbols):\n",
    "                processed_expr_ls[expr_id] += arg\n",
    "                continue\n",
    "            p = arg.as_poly()\n",
    "            monomial_exponents = p.monoms()[0]\n",
    "            \n",
    "            # only deal with non-linear monomials (order > 2)\n",
    "            if sum(monomial_exponents) <= 1:\n",
    "                processed_expr_ls[expr_id] += arg\n",
    "                continue\n",
    "\n",
    "            monomial = sympy.prod(x**k for x, k in zip(p.gens, monomial_exponents) \n",
    "                                  if not(x in scaler_symbols))\n",
    "            # check global substitution dictionary\n",
    "            if monomial in linearization_dict:\n",
    "                processed_expr_ls[expr_id] += arg.coeff(monomial)*linearization_dict[monomial]\n",
    "            else:\n",
    "                found = False\n",
    "                subs_monomial = create_symbol()\n",
    "                for symb in monomial.free_symbols:\n",
    "                    if symb in reverse_linearization_dict:\n",
    "                        equivalent_monomial = monomial.subs(symb, reverse_linearization_dict[symb])\n",
    "                        if equivalent_monomial in linearization_dict:\n",
    "                            subs_monomial = linearization_dict[equivalent_monomial]\n",
    "                            found = True\n",
    "                            break\n",
    "                linearization_dict[monomial] = subs_monomial\n",
    "                if not(found):\n",
    "                    reverse_linearization_dict[subs_monomial] = monomial\n",
    "                processed_expr_ls[expr_id] += arg.coeff(monomial)*subs_monomial\n",
    "                \n",
    "    return processed_expr_ls\n",
    "\n",
    "\n",
    "def merge_small_components_pca(expr_ls, budget=10):\n",
    "    if not(isinstance(expr_ls, sympy.Expr)):\n",
    "        expr_ls = sympy.Matrix(expr_ls)\n",
    "    if expr_ls.free_symbols:\n",
    "        center = expr_ls.subs(dict([(symb, 0) for symb in expr_ls.free_symbols]))\n",
    "    else:\n",
    "        return expr_ls\n",
    "    monomials_dict = get_generators(expr_ls)\n",
    "    generators = np.array([monomials_dict[m] for m in monomials_dict])\n",
    "    if len(generators) <= budget:\n",
    "        return expr_ls\n",
    "    monomials = [m for m in monomials_dict]\n",
    "    pca = PCA(n_components=len(generators[0]))\n",
    "    pca.fit(np.concatenate([generators, -generators]))\n",
    "    transformed_generators = pca.transform(generators)\n",
    "    transformed_generator_norms = np.linalg.norm(transformed_generators, axis=1, ord=2)\n",
    "    # from largest to lowest norm\n",
    "    sorted_indices = transformed_generator_norms.argsort()[::-1].astype(int)\n",
    "    sorted_transformed_generators = transformed_generators[sorted_indices]\n",
    "    sorted_monomials = [monomials[idx] for idx in sorted_indices]\n",
    "    new_transformed_generators = np.concatenate([sorted_transformed_generators[:budget], \n",
    "                                                 np.diag(np.sum(np.abs(sorted_transformed_generators[budget:]), \n",
    "                                                                axis=0))])\n",
    "    new_generators = pca.inverse_transform(new_transformed_generators)\n",
    "    new_monomials = sorted_monomials[:budget] + [create_symbol() for _ in range(len(generators[0]))]\n",
    "    \n",
    "    processed_expr_ls = center\n",
    "    for monomial_id in range(len(new_monomials)):\n",
    "        processed_expr_ls += sympy.Matrix(new_generators[monomial_id])*new_monomials[monomial_id]\n",
    "    \n",
    "    return processed_expr_ls\n",
    "\n",
    "\n",
    "def get_vertices(affset):\n",
    "    l = len(affset)\n",
    "    distinct_symbols = set()\n",
    "    for expr in affset:\n",
    "        if not(isinstance(expr, sympy.Expr)):\n",
    "            assert isinstance(expr, int) or isinstance(expr, float)\n",
    "        else:\n",
    "            if distinct_symbols:\n",
    "                distinct_symbols = distinct_symbols.union(expr.free_symbols)\n",
    "            else:\n",
    "                distinct_symbols = expr.free_symbols\n",
    "    distinct_symbols = list(distinct_symbols)\n",
    "    # print(distinct_symbols)\n",
    "    combs = [list(zip(distinct_symbols,list(l))) for l in list(itertools.product([-1, 1], repeat=len(distinct_symbols)))]\n",
    "    res = set()\n",
    "    for assignment in combs:\n",
    "        res.add(tuple([expr.subs(assignment) for expr in affset]))\n",
    "    return(res)\n",
    "\n",
    "\n",
    "# take a list of expressions as input, output the list of monomials and generator vectors,\n",
    "def get_generators(expr_ls):\n",
    "    monomials = dict()\n",
    "    for expr_id, expr in enumerate(expr_ls):\n",
    "        if not(isinstance(expr, sympy.Expr)) or not(expr.free_symbols):\n",
    "            continue\n",
    "        expr = expr.expand()\n",
    "        p = sympy.Poly(expr)\n",
    "        monomials_in_expr = [sympy.prod(x**k for x, k in zip(p.gens, mon)) \n",
    "                             for mon in p.monoms() if sum(mon) >= 1]\n",
    "        for monomial in monomials_in_expr:\n",
    "            coef = float(p.coeff_monomial(monomial))\n",
    "            if monomial in monomials:\n",
    "                if len(monomials[monomial]) < expr_id:\n",
    "                    monomials[monomial] = monomials[monomial] + [0 for _ in range(expr_id-len(monomials[monomial]))]\n",
    "                monomials[monomial].append(coef)\n",
    "            else:\n",
    "                monomials[monomial] = [0 for _ in range(expr_id)] + [coef]\n",
    "\n",
    "    for monomial in monomials:\n",
    "        if len(monomials[monomial]) < len(expr_ls):\n",
    "            monomials[monomial] = monomials[monomial] + [0 for _ in range(len(expr_ls)-len(monomials[monomial]))]\n",
    "    \n",
    "    return monomials\n",
    "\n",
    "\n",
    "def plot_conretiztion(affset, alpha = 0.5, color='red', budget=-1):\n",
    "    if budget > -1:\n",
    "        affset = merge_small_components_pca(affset, budget=budget)\n",
    "    pts = np.array(list(map(list, get_vertices(affset))))\n",
    "    hull = ConvexHull(pts)\n",
    "    plt.fill(pts[hull.vertices,0], pts[hull.vertices,1],color,alpha=alpha)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "def inject_ranges(X, y, uncertain_attr, uncertain_num, uncertain_radius_pct=None, \n",
    "                  uncertain_radius=None, seed=42):\n",
    "    global symbol_id\n",
    "    symbol_id = -1\n",
    "    \n",
    "    X_extended = np.append(np.ones((len(X), 1)), X, axis=1)\n",
    "    ss = StandardScaler()\n",
    "    X_extended[:, 1:] = ss.fit_transform(X_extended[:, 1:])\n",
    "    X_extended_symb = sympy.Matrix(X_extended)\n",
    "    \n",
    "    if not(uncertain_attr=='y'):\n",
    "        uncertain_attr_idx = X.columns.to_list().index(uncertain_attr) + 1\n",
    "        if not(uncertain_radius):\n",
    "            uncertain_radius = uncertain_radius_pct*(np.max(X_extended[:, uncertain_attr_idx])-\\\n",
    "                                                     np.min(X_extended[:, uncertain_attr_idx]))\n",
    "    else:\n",
    "        if not(uncertain_radius):\n",
    "            uncertain_radius = uncertain_radius_pct*(y_train.max()-y_train.min())[0]\n",
    "    \n",
    "    np.random.seed(seed)\n",
    "    uncertain_indices = np.random.choice(range(len(y)), uncertain_num, replace=False)\n",
    "    y_symb = sympy.Matrix(y)\n",
    "    symbols_in_data = set()\n",
    "    for uncertain_idx in uncertain_indices:\n",
    "        new_symb = create_symbol()\n",
    "        symbols_in_data.add(new_symb)\n",
    "        if uncertain_attr=='y':\n",
    "            y_symb[uncertain_idx] = y_symb[uncertain_idx] + uncertain_radius*new_symb\n",
    "        else:\n",
    "            X_extended_symb[uncertain_idx, uncertain_attr_idx] = X_extended_symb[uncertain_idx, uncertain_attr_idx] + uncertain_radius*new_symb\n",
    "    return X_extended_symb, y_symb, symbols_in_data, ss\n",
    "\n",
    "\n",
    "def sample_data_from_ranges(X, y, seed=42):\n",
    "    all_free_symbols = X.free_symbols.union(y.free_symbols)\n",
    "    subs_dict = dict()\n",
    "    np.random.seed(seed)\n",
    "    for symb in all_free_symbols:\n",
    "        subs_dict[symb] = (np.random.uniform()-.5)*2\n",
    "    return X.subs(subs_dict), y.subs(subs_dict)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Inject symbolic expressions (with uncertainty_radius=0.01) into all columns of X_calib:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Inject symbolic expressions (with uncertainty_radius=0.01) into all columns of X_calib:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X_calib' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 7\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Inject symbolic expressions into all columns of X_calib.\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m# We inject into each column using the inject_ranges function.\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# We use uncertain_num = len(X_calib) so that every row in the column gets an injection.\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m# First, inject for the first column and then update the remaining columns.\u001b[39;00m\n\u001b[1;32m      5\u001b[0m \n\u001b[1;32m      6\u001b[0m \u001b[38;5;66;03m# Inject for the first column\u001b[39;00m\n\u001b[0;32m----> 7\u001b[0m first_col \u001b[38;5;241m=\u001b[39m \u001b[43mX_calib\u001b[49m\u001b[38;5;241m.\u001b[39mcolumns[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m      8\u001b[0m X_calib_symb, y_calib_symb, injected_symbols, scaler_used \u001b[38;5;241m=\u001b[39m inject_ranges(\n\u001b[1;32m      9\u001b[0m     X_calib, y_calib, uncertain_attr\u001b[38;5;241m=\u001b[39mfirst_col, uncertain_num\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mlen\u001b[39m(X_calib),\n\u001b[1;32m     10\u001b[0m     uncertain_radius_pct\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, uncertain_radius\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.01\u001b[39m, seed\u001b[38;5;241m=\u001b[39mRANDOM_STATE\n\u001b[1;32m     11\u001b[0m )\n\u001b[1;32m     13\u001b[0m all_injected_symbols \u001b[38;5;241m=\u001b[39m injected_symbols\u001b[38;5;241m.\u001b[39mcopy()\n",
      "\u001b[0;31mNameError\u001b[0m: name 'X_calib' is not defined"
     ]
    }
   ],
   "source": [
    "# Inject symbolic expressions into all columns of X_calib.\n",
    "# We inject into each column using the inject_ranges function.\n",
    "# We use uncertain_num = len(X_calib) so that every row in the column gets an injection.\n",
    "# First, inject for the first column and then update the remaining columns.\n",
    "\n",
    "# Inject for the first column\n",
    "first_col = X_calib.columns[0]\n",
    "X_calib_symb, y_calib_symb, injected_symbols, scaler_used = inject_ranges(\n",
    "    X_calib, y_calib, uncertain_attr=first_col, uncertain_num=len(X_calib),\n",
    "    uncertain_radius_pct=None, uncertain_radius=0.01, seed=RANDOM_STATE\n",
    ")\n",
    "\n",
    "all_injected_symbols = injected_symbols.copy()\n",
    "\n",
    "# Inject for the remaining columns and update the corresponding column entries\n",
    "for col in X_calib.columns[1:]:\n",
    "    X_tmp, _, symbs_tmp, _ = inject_ranges(\n",
    "        X_calib, y_calib, uncertain_attr=col, uncertain_num=len(X_calib),\n",
    "        uncertain_radius_pct=None, uncertain_radius=0.01, seed=RANDOM_STATE\n",
    "    )\n",
    "    col_idx = X_calib.columns.to_list().index(col) + 1  # +1 due to prepended ones column\n",
    "    for i in range(len(X_calib)):\n",
    "        X_calib_symb[i, col_idx] = X_tmp[i, col_idx]\n",
    "    all_injected_symbols = all_injected_symbols.union(symbs_tmp)\n",
    "    \n",
    "# (Optional) Save all injected symbols into a dict for later reference\n",
    "y_symb_dict['X_calib'] = all_injected_symbols\n",
    "\n",
    "# Display a snippet of the symbolic matrix\n",
    "X_calib_symb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
